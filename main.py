import streamlit as st
import os
from langchain.memory import ConversationBufferMemory
from utils import qa_agent

st.title("ğŸ“‘ èŠ¯ç‰‡åˆ¶é€ çŸ¥è¯†åº“AIåŠ©æ‰‹")

with st.sidebar:
    st.header("é…ç½®è®¾ç½®")

    # ç¯å¢ƒå˜é‡å¯†é’¥
    env_key = os.getenv("OPENAI_API_KEY", "")

    # ç”¨æˆ·å¯†é’¥è¾“å…¥
    openai_api_key = st.text_input(
        "OpenAI APIå¯†é’¥ï¼š",
        type="password",
        value=env_key,
        help="ç®¡ç†å‘˜å·²é…ç½®å¯†é’¥æ—¶å¯ç•™ç©º" if env_key else None
    )

    # æ¨¡å‹é€‰æ‹©
    model_name = st.selectbox(
        "é€‰æ‹©AIæ¨¡å‹ï¼š",
        ["gpt-3.5-turbo", "gpt-4"],
        index=0
    )

    # APIåŸºåœ°å€
    api_base = st.text_input(
        "APIåŸºåœ°å€ï¼ˆå¯é€‰ï¼‰ï¼š",
        value=os.getenv("OPENAI_API_BASE", "https://api.aigc369.com/v1"),
        help="é»˜è®¤ä½¿ç”¨è¯¾ç¨‹æä¾›çš„APIåœ°å€"
    )

    if env_key:
        st.info("â„¹ï¸ æ£€æµ‹åˆ°é¢„é…ç½®å¯†é’¥ï¼Œè¾“å…¥æ¡†å¯ç•™ç©ºç›´æ¥ä½¿ç”¨")
    st.markdown("[è·å–APIå¯†é’¥](https://platform.openai.com/account/api-keys)")

# å¯†é’¥éªŒè¯
if not openai_api_key:
    if env_key:
        openai_api_key = env_key
    else:
        st.error("âŒ éœ€è¦æä¾›OpenAI APIå¯†é’¥ï¼ˆè¾“å…¥æˆ–ç¯å¢ƒå˜é‡ï¼‰")
        st.stop()

# åˆå§‹åŒ–ä¼šè¯å†…å­˜
if "memory" not in st.session_state:
    st.session_state["memory"] = ConversationBufferMemory(
        return_messages=True,
        memory_key="chat_history",
        output_key="answer"
    )

# æ–‡ä»¶ä¸Šä¼ å’Œæé—®
uploaded_file = st.file_uploader("ä¸Šä¼ èŠ¯ç‰‡åˆ¶é€ ç›¸å…³PDFæ–‡æ¡£", type="pdf")
question = st.text_input("è¯·è¾“å…¥æŠ€æœ¯é—®é¢˜", disabled=not uploaded_file)

if uploaded_file and question:
    with st.spinner("AIåˆ†æä¸­..."):
        response = qa_agent(
            openai_api_key,
            st.session_state["memory"],
            uploaded_file,
            question,
            model_name,
            api_base
        )
    st.write("### ä¸“å®¶è§£ç­”")
    st.write(response["answer"])
    st.session_state["chat_history"] = response["chat_history"]

# å†å²æ¶ˆæ¯å±•ç¤º
if "chat_history" in st.session_state:
    with st.expander("å¯¹è¯å†å²"):
        for i in range(0, len(st.session_state["chat_history"]), 2):
            human = st.session_state["chat_history"][i]
            ai = st.session_state["chat_history"][i + 1]
            st.markdown(f"**ç”¨æˆ·**ï¼š{human.content}")
            st.markdown(f"**AIä¸“å®¶**ï¼š{ai.content}")
            if i < len(st.session_state["chat_history"]) - 2:
                st.divider()